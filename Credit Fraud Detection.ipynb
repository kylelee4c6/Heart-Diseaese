{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Unbalanced Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is a collection of transactions made by credit cards in September 2013 by European cardholders. Over a period of two days,  transactions were aggregated by the Wordline and the Machine Learning Group of  Université Libre de Bruxelles and resulted in 492 out of 284,807 transactions being a fraud. Frauds account for .172% of all transactions. \n",
    "\n",
    "The goal of this notebook is to explore various undersampling and oversampling methods and the pipeline in order to produce the best model. Often, we assume binary classification problems have equally distributed response variables. Most of the time, however, it is not the case. \n",
    "\n",
    "We want to consider the following details about the dataset:\n",
    "- This dataset does not contain the original information as it is given as a result of a PCA transformation and the daata is classified.\n",
    "-  Features V1, V2, ..., V28 are the principal components while Time and Amount have not been transformed. \n",
    "- Time - seconds elapsed between each transaction and the first transaction in the dataset\n",
    "- Amount - transaction Amount\n",
    "- Class - Response variable \n",
    "    - 0 - No fraud\n",
    "    - 1 - Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. Obtain summary statistics and brief discussion about the data. \n",
    "2. Split data into train/test sets naively (because the response variables are skewed)\n",
    "3. Train several linear and non-linear models and see how well they perform.\n",
    "4. Consider oversampling, undersampling, and SMOTE-based preprocessing\n",
    "5. Analyze performance metrics by looking at some of the same algorithms, but uses newly processed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aznch\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\aznch\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credit = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_classes = credit[\"Class\"].value_counts().sort_index()\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is unbalanced. Therefore, we should consider other metrics besides accuracy to determine the best model. Precision, recall, and FScores would be more appropriate to use as metrics for this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exclude time and Amount\n",
    "X = credit.values[:,1:29].astype(float)\n",
    "Y = credit.values[:,30]\n",
    "validation_size = 0.3\n",
    "seed = 7\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y,test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 15\n",
    "num_instances = len(X_train)\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: 0.976659 (0.017884)\n",
      "ScaledLDA: 0.974522 (0.021750)\n",
      "ScaledKNN: 0.914807 (0.037333)\n",
      "ScaledCART: 0.868792 (0.048626)\n",
      "ScaledNB: 0.956314 (0.026760)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate scalers and models into pipeline\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR', LogisticRegression())])))\n",
    "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()),('LDA', LinearDiscriminantAnalysis())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsClassifier())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeClassifier())])))\n",
    "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()),('NB', GaussianNB())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring='roc_auc')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEVCAYAAADn6Y5lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyS372wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20aada286a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Scaled Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression and Linear Discriminant Analysis semed to work well based on our 15-fold cross validation set. However, note that on average, the Receiver operating characteristic area under curve average is .97. Of course this is high, but remember that our data contains about 99.8% non-fraud labels. So, the AUC reflects the biasness of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.978317 using {'C': 0.01}\n",
      "0.973330 (0.023045) with: {'C': 0.0001}\n",
      "0.975491 (0.021721) with: {'C': 0.001}\n",
      "0.978317 (0.019927) with: {'C': 0.01}\n",
      "0.978112 (0.018627) with: {'C': 0.1}\n",
      "0.976660 (0.017883) with: {'C': 1}\n",
      "0.976285 (0.017805) with: {'C': 10}\n",
      "0.976231 (0.017807) with: {'C': 100}\n",
      "0.976226 (0.017806) with: {'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Fine tune Logistic Regression\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "param_grid = {'C': [.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid, scoring='roc_auc', cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also consider the best hyperparameter $C$ in Logistic Regression. Let's see how well it does on our biased trained dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.99914562925\n",
      "[[85279     9]\n",
      " [   64    91]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     85288\n",
      "        1.0       0.91      0.59      0.71       155\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "0.713317597376\n"
     ]
    }
   ],
   "source": [
    "# Test LR model with C = .01\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = LogisticRegression(C=.01)\n",
    "model.fit(rescaledX, Y_train)\n",
    "\n",
    "# Test on cross validation set\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(\"Logistic Regression\")\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(\"Classification Report: \\n \", classification_report(Y_validation, predictions))\n",
    "print(cohen_kappa_score(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our recall rate is 59%. Accuracy is not a good measure in determining the fit of a model when we have a situation where our data is heavily unbalanced since frauds do not that often. This is because certain models such as CART are simple-rule based algorithms. We use the Cohen's Kappa score in order to observe that the Logistic Regression model achieved a rate of classification of 71% of the way between the expected accuracy and 100% accuracy.\n",
    "\n",
    "Now, a model like this has very limited use. It is more important for us to classify the true negatives correctly and without balancing the data, the models will lean biased toward classifying a case as true positive. Therefore, we resort to over-sampling techniques. One popular technique is called SMOTE (Synthetic Minority Oversampling Technique). This creates versions of the minority class (in this case, the frauds) by finding similar observations using k-Nearest Neighbors and tweaking the observations. Thanks for the wisdom, Nick! (https://beckernick.github.io/oversampling-modeling/)\n",
    "\n",
    "Now it is important to identify when we are going to perform SMOTE because if we did that to the whole dataset, what will happen is that information will bleed. If I performed SMOTE first before splitting into my train/test sets, the synthetic observations that may be classified as part of the training set may be based on some observation that is reserved for the test set. Remember, we want to keep the splits separately which means the information from any modification should be partitioned accordingly. I will think of a good analogy for this later that is probably in relation to creating a small party of people.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=12)\n",
    "X_train_sm, Y_train_sm = sm.fit_sample(X_train, Y_train)\n",
    "randomize = np.arange(len(X_train_sm))\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "# Permute values for kfold, otherwise we obtain a one-class error since SMOTE splits the classes in half.\n",
    "X_train_sm = X_train_sm[randomize]\n",
    "Y_train_sm = Y_train_sm[randomize]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 15\n",
    "num_instances_sm = len(X_train_sm)\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_sm))\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.987113 using {'C': 100}\n",
      "0.980792 (0.000712) with: {'C': 0.0001}\n",
      "0.983578 (0.000582) with: {'C': 0.001}\n",
      "0.984879 (0.000539) with: {'C': 0.01}\n",
      "0.986326 (0.000488) with: {'C': 0.1}\n",
      "0.987010 (0.000466) with: {'C': 1}\n",
      "0.987102 (0.000460) with: {'C': 10}\n",
      "0.987113 (0.000461) with: {'C': 100}\n",
      "0.987112 (0.000460) with: {'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Fine tune Logistic Regression\n",
    "scaler = StandardScaler().fit(X_train_sm)\n",
    "rescaledX_sm = scaler.transform(X_train_sm)\n",
    "param_grid = {'C': [.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "kfold = cross_validation.KFold(n=num_instances_sm, n_folds=15, random_state=seed)\n",
    "\n",
    "grid = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid, scoring='roc_auc', cv=kfold)\n",
    "grid_result = grid.fit(rescaledX_sm, Y_train_sm)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.973467691912\n",
      "[[83034  2254]\n",
      " [   13   142]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.97      0.99     85288\n",
      "        1.0       0.06      0.92      0.11       155\n",
      "\n",
      "avg / total       1.00      0.97      0.98     85443\n",
      "\n",
      "0.108290209736\n"
     ]
    }
   ],
   "source": [
    "# Test LR model with C = 100\n",
    "scaler = StandardScaler().fit(X_train_sm)\n",
    "rescaledX_sm = scaler.transform(X_train_sm)\n",
    "model = LogisticRegression(C=100)\n",
    "model.fit(rescaledX_sm, Y_train_sm)\n",
    "\n",
    "# Test on cross validation set\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(\"Logistic Regression\")\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))\n",
    "print(cohen_kappa_score(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now note that our precision for fraud is only 6%. This is disappointing. So I'll try some other sampling methods \n",
    "// TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors\n",
    "I wanted to try how k-Nearest Neigbors would act."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors\n",
      "0.992275552122\n",
      "[[84647   641]\n",
      " [   19   136]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00     85288\n",
      "        1.0       0.18      0.88      0.29       155\n",
      "\n",
      "avg / total       1.00      0.99      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test kNN with 15 neighbors\n",
    "model3 =  KNeighborsClassifier(n_neighbors = 15)\n",
    "model3.fit(rescaledX_sm, Y_train_sm)\n",
    "predictions3 = model3.predict(rescaledValidationX)\n",
    "\n",
    "print( \"k-Nearest Neighbors\")\n",
    "print(accuracy_score(Y_validation, predictions3))\n",
    "print(confusion_matrix(Y_validation, predictions3))\n",
    "print(classification_report(Y_validation, predictions3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_folds = 15\n",
    "num_instances_sm = len(X_train_sm)\n",
    "seed = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train_sm)\n",
    "rescaledX_sm = scaler.transform(X_train_sm)\n",
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(rescaledX_sm, Y_train_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis with SMOTE\n",
      "0.98492562293\n",
      "[[84024  1264]\n",
      " [   24   131]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      0.99     85288\n",
      "        1.0       0.09      0.85      0.17       155\n",
      "\n",
      "avg / total       1.00      0.98      0.99     85443\n",
      "\n",
      "0.166309981046\n"
     ]
    }
   ],
   "source": [
    "# Test on cross validation set\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(\"Linear Discriminant Analysis with SMOTE\")\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))\n",
    "print(cohen_kappa_score(Y_validation, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
